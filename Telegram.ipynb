{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astepankoff/gigachat_tutorials/blob/main/Telegram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подключение Гигачата к собственному боту в Telegram\n",
        "В рамках этого туториала мы изучим два вопроса:\n",
        "- Использование возможностей LangChain для управления памятью в рамках диалога;\n",
        "- Взаимодействие бота и языковой модели (передача сообщения пользователя в языковую модель и отправка ответа модели в бота).\n",
        "## Получение токена бота\n",
        "\n",
        "Нам понадобится свой бот. Если вы не создавали ботов в Telegram ранее, то выполните следующие шаги:\n",
        "\n",
        "   - Найдите в Telegram аккаунт [@BotFather](https://t.me/BotFather).\n",
        "   - Напишите ему команду `/newbot`.\n",
        "   - Следуйте инструкциям BotFather для выбора имени (может быть любое) и username вашего бота (это уникальный идентификатор и часть url бота, который должен содержать \"bot\" в своем названии).\n",
        "   - После создания бота BotFather предоставит вам токен для доступа к Telegram Bot API."
      ],
      "metadata": {
        "id": "1Bm8qJuUilsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Устанавливаем требуемые библиотеки\n",
        "Существует большое количество библиотек для работы с ботами Telegram. Мы в этом туториале будем использовать [pyTelegramBotAPI](https://github.com/eternnoir/pyTelegramBotAPI). Если вам превычнее работать с другой библиотекой, используйте свой вариант.\n",
        "\n",
        "Также нам понадобится уже знакомая нам по [прошлому туториалу](https://youtu.be/eo5LyjRobic) библиотека [GigaChain](https://github.com/ai-forever/gigachain)."
      ],
      "metadata": {
        "id": "lJR2_Or3kW9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyTelegramBotAPI\n",
        "!pip install -q gigachain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXQecu8Em8rE",
        "outputId": "432707e0-9dd5-49ca-a754-cc8841a4d1c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.7/290.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импортируем ключи\n",
        "Нам понадобится токен от бота и ключ для авторизации в Гигачат. Я дляэтого использую встроенные в Сolab секреты."
      ],
      "metadata": {
        "id": "hY3wHC-5IJ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "sber = userdata.get('SBER_AUTH')\n",
        "bot_token = userdata.get('BOT_TOKEN')"
      ],
      "metadata": {
        "id": "FEup6MLLIIxM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Работа с памятью (контекстным окном) в LangChain\n",
        "Прежде чем подключать GigaChat к боту, давайте просто через взаимодействие с языковой моделью изучим возможности LangChain в плане \"памяти\" (хранения сообщений и/или общего контекста диалога)\n",
        "\n",
        "Подробно про память в LangChain можно почитать в [документации](https://python.langchain.com/docs/modules/memory/).\n",
        "\n",
        "Языковые модели не обладают памятью. Они просто генерируют новый текст на основании текста, который был передан им в качестве промпта. Текст промпта может содержать весь диалог, начиная с системного сообщения или первого сообщения пользователя. Однако тогда каждое последующее сообщение от пользователя будет предворятся все более длинным текстом истории диалога. Это чревато большим расходом токенов и грозит в какой-то момент превысить размер контекстного окна.\n",
        "\n",
        "Чтобы не превысить размеры окна и сэкономить на расходе токенов LangChain предлагает различные типы памяти. Перечислим основные из них:\n",
        "- [`ConversationBufferMemory`](https://python.langchain.com/docs/modules/memory/types/buffer) - самый простой вариант. Позволяет хранить, записывать и передавать в переменные сообщения из диалога.\n",
        "- [`ConversationBufferWindowMemory`](https://python.langchain.com/docs/modules/memory/types/buffer_window) - почти тоже самое, что и `ConversationBufferMemory`, но держит в памяти только k последних пар сообщений (под парой понимается пользовательский запрос и ответ языковой модели). Получается такое своего рода скользящее окно.\n",
        "- [`ConversationEntityMemory`](https://python.langchain.com/docs/modules/memory/types/entity_summary_memory) - помимо истории сообщений создает еще хранилище отдельных сущностей (entities), которые попадаются в ходе диалога. Поучается, что помимо неструктурированного текста языковая модель работает и со структурированными извлеченными сущностями.\n",
        "- [`ConversationKGMemory`](https://python.langchain.com/docs/modules/memory/types/kg) - память в виде графа знаний.\n",
        "- [`ConversationSummaryMemory`](https://python.langchain.com/docs/modules/memory/types/summary) - память в виде краткого содержания разговора. Сами сообщения не хранятся, просто языковая модель регулярно пополняет память новыми деталями из свежих сообщений диалога.\n",
        "- [`ConversationSummaryBufferMemory`](https://python.langchain.com/docs/modules/memory/types/summary_buffer) - хранит и некоторое количество сообщений диалога, и краткое описание всей беседы в целом.\n",
        "- [`ConversationTokenBufferMemory`]() - подобно `ConversationBufferWindowMemory` хранит ограниченное количество сообщений, но здесь вместо лимита по количеству сообщений лимит по количеству токенов.\n",
        "- [`VectorStoreRetrieverMemory`](https://python.langchain.com/docs/modules/memory/types/vectorstore_retriever_memory) - отправляет сообщения в векторное хранилище. Там сообщения хранятся произвольно, отпраляясь в контекст диалога только если они семантически релевантны сообщению пользователя.   "
      ],
      "metadata": {
        "id": "0_JAdfuzn-g2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сравнение обычной памяти и памяти с извлеченными сущностями\n",
        "\n",
        "Для экономии времени в этом туториале мы рассмотрим лишь `ConversationBufferMemory` и `ConversationEntityMemory`.\n",
        "\n",
        "Для удобства работы с диалогами мы используем [`ConversationChain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.conversation.base.ConversationChain.html). Это удобный инструмент, чтобы соединить память и языковую модель.\n",
        "\n",
        "#### ConversationBufferMemory"
      ],
      "metadata": {
        "id": "SEE_WUBbRFan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community\n",
        "!pip install gigachat"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AikEozP3e4v1",
        "outputId": "900c47ff-8011-4ed0-8d85-ca3f8b70673b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.74)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.14)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Collecting gigachat\n",
            "  Downloading gigachat-0.1.42.post1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: httpx<1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=1 in /usr/local/lib/python3.12/dist-packages (from gigachat) (2.11.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1->gigachat) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1->gigachat) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1->gigachat) (0.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1->gigachat) (1.3.1)\n",
            "Downloading gigachat-0.1.42.post1-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.4/69.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gigachat\n",
            "Successfully installed gigachat-0.1.42.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models.gigachat import GigaChat\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm = GigaChat(credentials=sber, verify_ssl_certs=False)\n",
        "conversation1 = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ],
      "metadata": {
        "id": "ymBJt_QYSfjq",
        "outputId": "8edfa45e-7b53-4e09-eaf7-3a9b59f65a4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2105212129.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory=ConversationBufferMemory()\n",
            "/tmp/ipython-input-2105212129.py:6: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
            "  conversation1 = ConversationChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем несколько сообщений языковой модели и посмотрим, что именно хранится в памяти."
      ],
      "metadata": {
        "id": "84IDh7O4UIT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation1.predict(input='Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "3IU3FGFvUXLH",
        "outputId": "426b106a-2374-47f2-d8c6-79d29816aa57"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Привет, Сергей!\\n\\nРад слышать, что ты снимаешь видео про GigaChat и Python — отличная тема! Если тебе нужно немного вдохновения или помощь с идеями сценария, расскажу пару вещей, которые точно пригодятся.\\n\\n1. **Краткий обзор GigaChat**: Можешь рассказать, как работает нейросетевой помощник и какие основные функции у него есть (например, помощь с кодом, анализ текста, генерация контента).\\n   \\n2. **Практический пример программирования на Python**: Покажи простой скрипт, который решает конкретную задачу (например, работа с файлами, обработка изображений или даже генерация небольших изображений). Можно показать процесс написания кода от начала до конца.\\n\\n3. **Советы начинающим разработчикам**: Упомяни несколько полезных ресурсов или библиотек Python, которые помогут новичкам начать писать эффективные программы.\\n\\n4. **Заключение и призыв к действию**: Закончись мотивирующим роликом или предложением посмотреть другие твои видео, где рассматриваются аналогичные темы.\\n\\nНадеюсь, эти идеи помогут сделать твоё видео интересным и полезным! Если понадобится дополнительная информация по Python или другим аспектам разработки, обращайся.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation1.predict(input='Какая большая языковая модель самая лучшая?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "0QqW8EEZVCy-",
        "outputId": "9b1bdb42-d123-4b2c-da56-aaaa0c841b6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей!\n",
            "\n",
            "Рад слышать, что ты снимаешь видео про GigaChat и Python — отличная тема! Если тебе нужно немного вдохновения или помощь с идеями сценария, расскажу пару вещей, которые точно пригодятся.\n",
            "\n",
            "1. **Краткий обзор GigaChat**: Можешь рассказать, как работает нейросетевой помощник и какие основные функции у него есть (например, помощь с кодом, анализ текста, генерация контента).\n",
            "   \n",
            "2. **Практический пример программирования на Python**: Покажи простой скрипт, который решает конкретную задачу (например, работа с файлами, обработка изображений или даже генерация небольших изображений). Можно показать процесс написания кода от начала до конца.\n",
            "\n",
            "3. **Советы начинающим разработчикам**: Упомяни несколько полезных ресурсов или библиотек Python, которые помогут новичкам начать писать эффективные программы.\n",
            "\n",
            "4. **Заключение и призыв к действию**: Закончись мотивирующим роликом или предложением посмотреть другие твои видео, где рассматриваются аналогичные темы.\n",
            "\n",
            "Надеюсь, эти идеи помогут сделать твоё видео интересным и полезным! Если понадобится дополнительная информация по Python или другим аспектам разработки, обращайся.\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[Объяснение вопроса]\\n\\nВопрос касается выбора лучшей большой языковой модели (LLM), и сразу стоит отметить, что понятие «лучшая» зависит от контекста и целей конкретного пользователя. Различные LLM обладают разными сильными сторонами и особенностями, подходящими для разных сценариев использования.\\n\\n- Для некоторых пользователей важнее высокая точность и аккуратность в ответах, особенно когда речь идет о профессиональной деятельности, связанной с юридической консультацией, медицинской диагностикой или техническим проектированием.\\n- Другим же пользователям важнее креативность и гибкость, чтобы получать интересные и нестандартные решения в области творчества, развлечений и общения.\\n\\nПоэтому вопрос сводится к личным предпочтениям и целям, а также возможностям конкретной модели.\\n\\n### Сравнение нескольких популярных моделей\\n\\n#### 1. GigaChat (Russian)\\n- **Сильные стороны:** Очень хорошо адаптирован к русскоязычным данным, культурным особенностям и российским реалиям. Легко справляется с задачами анализа русского языка, генерации контента и помощи в разработке на русском.\\n- **Недостатки:** Относительно новая модель, ещё не обладает таким опытом работы с большими объемами англоязычных данных, как некоторые зарубежные аналоги.\\n\\n#### 2. ChatGPT (OpenAI)\\n- **Сильные стороны:** Широко распространена и используется во многих странах мира. Отличается высокой точностью и универсальностью благодаря большому объему обучающих данных и мощной инфраструктуре OpenAI.\\n- **Недостатки:** Иногда менее чувствителен к русским культурным контекстам и специфике русского языка.\\n\\n#### 3. PaLM (Google)\\n- **Сильные стороны:** Известна своей производительностью и стабильностью. Обладает высокими показателями точности и предсказуемости, легко адаптируется под разные запросы.\\n- **Недостатки:** Меньше русскоязычной адаптации, хотя активно развивается.\\n\\n#### 4. LLAMSA (Sber AI)\\n- **Сильные стороны:** Разработана специально для российского рынка и идеально подходит для решения прикладных задач на русском языке. Поддерживает обучение на специализированных корпоративных данных.\\n- **Недостатки:** Пока ограниченный доступ и развитие преимущественно внутри экосистемы компании-разработчика.\\n\\n---\\n\\n### Подходящий выбор\\nЕсли основная цель — использование модели для русскоязычного контента, рекомендаций будет достаточно выбрать между GigaChat и LLAMSA, учитывая доступные ресурсы и цели проекта.\\n\\nЕсли же задача требует глобального охвата и международного уровня коммуникации, лучше остановиться на ChatGPT или PaLM, обеспечивающих лучшую международную поддержку и масштабируемость.\\n\\nКакой конкретно сценарий тебя интересует?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation1.predict(input='Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H_b8WSbfVXU7",
        "outputId": "9619cfa6-b08c-4b77-d3be-b7ba011bc279"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей!\n",
            "\n",
            "Рад слышать, что ты снимаешь видео про GigaChat и Python — отличная тема! Если тебе нужно немного вдохновения или помощь с идеями сценария, расскажу пару вещей, которые точно пригодятся.\n",
            "\n",
            "1. **Краткий обзор GigaChat**: Можешь рассказать, как работает нейросетевой помощник и какие основные функции у него есть (например, помощь с кодом, анализ текста, генерация контента).\n",
            "   \n",
            "2. **Практический пример программирования на Python**: Покажи простой скрипт, который решает конкретную задачу (например, работа с файлами, обработка изображений или даже генерация небольших изображений). Можно показать процесс написания кода от начала до конца.\n",
            "\n",
            "3. **Советы начинающим разработчикам**: Упомяни несколько полезных ресурсов или библиотек Python, которые помогут новичкам начать писать эффективные программы.\n",
            "\n",
            "4. **Заключение и призыв к действию**: Закончись мотивирующим роликом или предложением посмотреть другие твои видео, где рассматриваются аналогичные темы.\n",
            "\n",
            "Надеюсь, эти идеи помогут сделать твоё видео интересным и полезным! Если понадобится дополнительная информация по Python или другим аспектам разработки, обращайся.\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "AI: [Объяснение вопроса]\n",
            "\n",
            "Вопрос касается выбора лучшей большой языковой модели (LLM), и сразу стоит отметить, что понятие «лучшая» зависит от контекста и целей конкретного пользователя. Различные LLM обладают разными сильными сторонами и особенностями, подходящими для разных сценариев использования.\n",
            "\n",
            "- Для некоторых пользователей важнее высокая точность и аккуратность в ответах, особенно когда речь идет о профессиональной деятельности, связанной с юридической консультацией, медицинской диагностикой или техническим проектированием.\n",
            "- Другим же пользователям важнее креативность и гибкость, чтобы получать интересные и нестандартные решения в области творчества, развлечений и общения.\n",
            "\n",
            "Поэтому вопрос сводится к личным предпочтениям и целям, а также возможностям конкретной модели.\n",
            "\n",
            "### Сравнение нескольких популярных моделей\n",
            "\n",
            "#### 1. GigaChat (Russian)\n",
            "- **Сильные стороны:** Очень хорошо адаптирован к русскоязычным данным, культурным особенностям и российским реалиям. Легко справляется с задачами анализа русского языка, генерации контента и помощи в разработке на русском.\n",
            "- **Недостатки:** Относительно новая модель, ещё не обладает таким опытом работы с большими объемами англоязычных данных, как некоторые зарубежные аналоги.\n",
            "\n",
            "#### 2. ChatGPT (OpenAI)\n",
            "- **Сильные стороны:** Широко распространена и используется во многих странах мира. Отличается высокой точностью и универсальностью благодаря большому объему обучающих данных и мощной инфраструктуре OpenAI.\n",
            "- **Недостатки:** Иногда менее чувствителен к русским культурным контекстам и специфике русского языка.\n",
            "\n",
            "#### 3. PaLM (Google)\n",
            "- **Сильные стороны:** Известна своей производительностью и стабильностью. Обладает высокими показателями точности и предсказуемости, легко адаптируется под разные запросы.\n",
            "- **Недостатки:** Меньше русскоязычной адаптации, хотя активно развивается.\n",
            "\n",
            "#### 4. LLAMSA (Sber AI)\n",
            "- **Сильные стороны:** Разработана специально для российского рынка и идеально подходит для решения прикладных задач на русском языке. Поддерживает обучение на специализированных корпоративных данных.\n",
            "- **Недостатки:** Пока ограниченный доступ и развитие преимущественно внутри экосистемы компании-разработчика.\n",
            "\n",
            "---\n",
            "\n",
            "### Подходящий выбор\n",
            "Если основная цель — использование модели для русскоязычного контента, рекомендаций будет достаточно выбрать между GigaChat и LLAMSA, учитывая доступные ресурсы и цели проекта.\n",
            "\n",
            "Если же задача требует глобального охвата и международного уровня коммуникации, лучше остановиться на ChatGPT или PaLM, обеспечивающих лучшую международную поддержку и масштабируемость.\n",
            "\n",
            "Какой конкретно сценарий тебя интересует?\n",
            "Human: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Какие бесплатные большие языковые модели подходят для работы с русским языком?\\n\\nЕсли хочешь использовать бесплатные нейросети для работы с русским текстом, существует несколько достойных вариантов, каждый из которых имеет свои особенности и преимущества:\\n\\n## 1. **GigaChat**\\n   - **Описание:** Модель разработана компанией Sber AI и ориентирована именно на русский язык. Она отлично подходит для русскоязычных пользователей, предлагая высокую точность и надежность.\\n   - **Особенности:** \\n     - Высокая чувствительность к русской культуре и современным реалиям.\\n     - Простота интеграции в различные проекты и приложения.\\n   - **Использование:** Бесплатная версия доступна через API или сайт GigaChat, обеспечивая возможность создавать и анализировать тексты, помогать с программированием и решать аналитические задачи.\\n\\n## 2. **LaMDA**\\n   - **Описание:** Нейросеть создана Google и широко известна своим высоким уровнем точности и обширной базой знаний.\\n   - **Особенности:**\\n     - Поддержка множества языков, включая русский.\\n     - Хорошо подходит для сложных запросов и высокоуровневого анализа текстов.\\n   - **Доступность:** Бесплатный доступ возможен через специальные API или публичные демонстрации, однако интеграция в собственные продукты потребует лицензионного соглашения.\\n\\n## 3. **DeepPavlov**\\n   - **Описание:** Открытая исследовательская платформа, созданная российскими учеными. Основной акцент сделан на русскоязычные задачи обработки естественного языка.\\n   - **Особенности:**\\n     - Свободное распространение и доступность исходного кода.\\n     - Возможность кастомизации под конкретные нужды проектов.\\n   - **Применение:** Подходит для широкого спектра задач, связанных с NLP, начиная от простого распознавания смысла предложений и заканчивая сложными системами чат-ботов.\\n\\n## 4. **BERT-Russian**\\n   - **Описание:** Модификация популярной архитектуры BERT, адаптированная для русского языка.\\n   - **Особенности:**\\n     - Эффективна для задач классификации текстов, понимания намерений и поиска релевантной информации.\\n     - Открытый доступ к библиотеке PyTorch и возможности глубокого погружения в работу модели.\\n   - **Преимущества:** Идеально подходит для академических исследований и стартапов, стремящихся к созданию инновационных решений в сфере NLP.\\n\\n## 5. **RuDPR**\\n   - **Описание:** Крупнейшая предобученная русская модель, обладающая мощным потенциалом в понимании контекста и точного прогнозирования смыслов.\\n   - **Особенности:**\\n     - Полноценная поддержка русского языка с учетом всех тонкостей.\\n     - Глубокое понимание диалоговых конструкций и умение вести осмысленные беседы.\\n   - **Удобство использования:** Доступна через публичные API, предоставляющие удобный интерфейс взаимодействия.\\n\\n---\\n\\n## Вывод\\nДля тех, кто ищет бесплатную русскоязычную нейросеть, оптимальными вариантами будут **GigaChat** и **BERT-Russian**. Они предлагают баланс между качеством, поддержкой русского языка и простотой внедрения в существующие проекты. \\n\\nЕсли нужна максимальная свобода действий и гибкость в настройке системы, можно рассмотреть **DeepPavlov**, хотя она требует большего объема усилий на интеграцию и разработку.\\n\\nТаким образом, каждая из предложенных моделей обладает своими преимуществами и подойдет для конкретных целей и бюджетов.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation1.predict(input='Как меня зовут и чем я занимаюсь?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Gke-b9F4V4Xy",
        "outputId": "5528d647-02ec-4d1e-f208-d6e151fc571a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mНиже приводится дружеский разговор между человеком и AI. AI разговорчив и предоставляет множество конкретных деталей из своего контекста. Если AI не знает ответа на вопрос, он честно говорит, что не знает.\n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей! Очень приятно познакомиться. Я - GigaChat, виртуальный помощник, разработанный Сбером в России. Я могу помочь вам с различными вопросами и задачами, связанными с Python и машинным обучением. Если у вас есть какие-либо вопросы или нужна помощь, я готов помочь вам.\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "AI: Это сложный вопрос, так как \"лучшая\" языковая модель зависит от многих факторов, таких как точность, скорость, размер и область применения. Некоторые из самых известных и мощных языковых моделей включают GPT-3 от OpenAI, BERT от Google, T5 от Microsoft и Transformer-XL от Facebook. Однако, выбор лучшей модели может зависеть от ваших конкретных потребностей и целей. Если у вас есть более конкретные вопросы или задачи, я буду рад помочь вам.\n",
            "Human: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.\n",
            "AI: В настоящее время GigaChat не предоставляет бесплатную версию для использования на русском языке. Однако, вы можете использовать другие языковые модели, такие как GPT-3 или BERT, которые поддерживают русский язык и могут быть доступны бесплатно.\n",
            "Human: Как меня зовут и чем я занимаюсь?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ваше имя - Сергей, и вы занимаетесь записью видео про GigaChat и Python.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ConversationEntityMemory\n",
        "Теперь реализуем точно такой же диалог, но с другим видом памяти."
      ],
      "metadata": {
        "id": "jO-oC1x-WHhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models.gigachat import GigaChat\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
        "from langchain.memory import ConversationEntityMemory\n",
        "\n",
        "llm = GigaChat(credentials=sber, verify_ssl_certs=False)\n",
        "conversation2 = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=llm)\n",
        ")"
      ],
      "metadata": {
        "id": "cZIImrnFH5qx",
        "outputId": "a07e25a6-5c25-4c08-b5e0-1527567eae1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1490275723.py:11: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory=ConversationEntityMemory(llm=llm)\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/main.py:253: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2.predict(input='Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "PpCCgRpIJUld",
        "outputId": "fd987b90-ea96-42c3-8305-61ea0371f70d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'GigaChat': 'Сергей снимает видео о работе с GigaChat и языком программирования Python.', 'Python': 'Сергей снимает видео, посвященное работе с GigaChat и изучению языка программирования Python.', 'Сергей': 'Сергей — автор видеоролика о работе с GigaChat и языком программирования Python.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей!\n",
            "\n",
            "Рад слышать, что ты снимаешь видео про GigaChat и Python — отличная тема! Если тебе нужно обсудить какие-то конкретные моменты, задать вопрос или получить помощь с кодом или объяснениями, обращайся. Например, можешь рассказать подробнее, какую тему планируешь раскрыть в видео? Или уточнить, есть ли какие-то особенности работы с GigaChat или сложившиеся трудности в изучении Python, которые хотелось бы разобрать подробнее?\n",
            "Last line:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Привет, Сергей!\\n\\nЗдорово, что выбрал такую интересную тему для видео! Думаю, многим будет полезно узнать больше о применении GigaChat вместе с Python. Расскажи подробнее, над какой именно задачей или примером собираешься поработать в своем ролике? Может быть, хочешь показать взаимодействие между GigaChat и Python-кодом в реальной ситуации (например, автоматизация каких-то рутинных процессов)? Или же акцент делаешь на конкретных аспектах изучения Python с помощью GigaChat (поиск подсказок, примеров кода, быстрое решение задач через диалоговые интерфейсы)? \\n\\nМогу помочь с любыми вопросами по языку программирования Python или объяснить нюансы взаимодействия GigaChat с различными API и библиотеками.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2.predict(input='Какая большая языковая модель самая лучшая?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "10630e95-8912-435d-84e9-a9b2db7dcdd1",
        "id": "BC2V0K9kWsvG"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'GigaChat': 'Сергей записывает видео, демонстрирующее применение GigaChat совместно с языком программирования Python.', 'Python': 'Сергей снимает видео, рассказывающее о применении GigaChat совместно с изучением и практическим использованием языка программирования Python.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей!\n",
            "\n",
            "Рад слышать, что ты снимаешь видео про GigaChat и Python — отличная тема! Если тебе нужно обсудить какие-то конкретные моменты, задать вопрос или получить помощь с кодом или объяснениями, обращайся. Например, можешь рассказать подробнее, какую тему планируешь раскрыть в видео? Или уточнить, есть ли какие-то особенности работы с GigaChat или сложившиеся трудности в изучении Python, которые хотелось бы разобрать подробнее?\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей!\n",
            "\n",
            "Здорово, что выбрал такую интересную тему для видео! Думаю, многим будет полезно узнать больше о применении GigaChat вместе с Python. Расскажи подробнее, над какой именно задачей или примером собираешься поработать в своем ролике? Может быть, хочешь показать взаимодействие между GigaChat и Python-кодом в реальной ситуации (например, автоматизация каких-то рутинных процессов)? Или же акцент делаешь на конкретных аспектах изучения Python с помощью GigaChat (поиск подсказок, примеров кода, быстрое решение задач через диалоговые интерфейсы)? \n",
            "\n",
            "Могу помочь с любыми вопросами по языку программирования Python или объяснить нюансы взаимодействия GigaChat с различными API и библиотеками.\n",
            "Last line:\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Большая языковая модель сама по себе не может быть однозначно названа лучшей, поскольку понятие «лучшая» зависит от конкретной цели и области применения. Разные модели обладают своими сильными сторонами и особенностями, и выбор подходящей модели зависит от специфики решаемой задачи.\\n\\n### Вот несколько популярных моделей, каждая из которых выделяется в своей нише:\\n\\n1. **OpenAI GPT-4**  \\n   Самая передовая и универсальная модель общего назначения, хорошо справляющаяся с широким спектром задач — от творческих до аналитических и технических. Она умеет понимать контекст, строить рассуждения и давать осмысленные ответы даже на сложные запросы.\\n\\n2. **Google Bard / PaLM**  \\n   Модель Google известна своим высоким уровнем точности и хорошей работой с естественным языком. Ее отличают аккуратность и глубокое понимание структуры текста, она хороша для точной обработки информации и решения узкоспециализированных задач.\\n\\n3. **Sber AI GigaChat**  \\n   Российская разработка, ориентированная на русскоязычную аудиторию и обеспечивающая высокое качество русского языка и культурной адаптации. Отличается быстрой реакцией и пониманием нюансов русского общения.\\n\\n4. **LLaMA (Large Language Model Meta AI)**  \\n   Открытая исследовательская модель, разработанная Meta AI, доступная широкой аудитории для экспериментов и кастомизации. Хороший вариант для тех, кто хочет исследовать возможности больших языковых моделей самостоятельно.\\n\\n5. **BERT и RoBERTa**  \\n   Модели трансформеров, специализирующиеся на понимании контекста и анализе естественного языка. Они особенно полезны для анализа текста, классификации, поиска и машинного перевода.\\n\\n6. **T5/TRAIT/FLAN**  \\n   Семейство моделей, специально оптимизированных для задач NLP, где важно выполнение инструкций, перевод и автоматическое создание контента. Эти модели подходят для выполнения сложных многошаговых заданий.\\n\\n### Какой выбрать?\\n\\nВыбирай модель исходя из целей своего проекта:\\n- Для глубокого понимания русской культуры и стиля общения лучше подойдет **GigaChat**.\\n- Для технической документации, технического перевода или аналитики английского текста стоит рассмотреть **Bard/PaLM**.\\n- Если хочется разобраться самому и покопаться в возможностях LLM, обратись к **LLaMA**, который открыт для исследования.\\n\\nКаждая из упомянутых моделей обладает уникальными достоинствами, и правильный выбор зависит от твоих потребностей и задачи.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2.predict(input='Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "dc264563-54a2-46cb-bc75-542cb0632008",
        "id": "cqHlp3fqWsvV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mТы помощник человека, работающий на большой языковой модели, обученной OpenAI.\n",
            "\n",
            "Ты спроектирован, чтобы помогать в широком диапазоне задач, от ответов на простые вопросы до предоставления подробных объяснений и обсуждений на самые разные темы. Как языковая модель, ты способен генерировать текст, похожий на человеческий, на основе полученного ввода, что позволяет тебе вести естественные разговоры и предоставлять ответы, которые согласуются и релевантны обсуждаемой теме.\n",
            "\n",
            "Ты постоянно учишься и совершенствуешься, и твои способности постоянно эволюционируют. Ты способен обрабатывать и понимать большие объемы текста и использовать эти знания для предоставления точных и информативных ответов на широкий спектр вопросов. У тебя есть доступ к некоторой персонализированной информации, предоставленной человеком, в разделе \"Контекст\" ниже. Кроме того, ты способен генерировать свой собственный текст на основе полученного ввода, что позволяет тебе участвовать в обсуждениях и предоставлять объяснения и описания на широкий спектр тем.\n",
            "\n",
            "В целом, ты мощный инструмент, который может помочь в широком диапазоне задач и предоставить ценные сведения и информацию по широкому спектру тем. Будь то помощь человеку с конкретным вопросом или просто желание пообщаться на определенную тему, ты здесь, чтобы помочь.\n",
            "\n",
            "Контекст:\n",
            "{'GPT-3': '', 'OpenAI': ''}\n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей! Рад познакомиться. Расскажи, пожалуйста, что именно ты хочешь узнать о GigaChat и Python? Я буду рад помочь тебе с любыми вопросами или обсуждениями, которые у тебя есть.\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "AI: Вопрос о том, какая большая языковая модель является лучшей, является сложным и субъективным, так как эффективность модели зависит от множества факторов, включая ее способность обрабатывать различные типы данных, точность и скорость обработки, а также ее применимость к конкретной задаче.\n",
            "\n",
            "Существует множество больших языковых моделей, таких как GPT-3, T5, BERT, Transformer и другие, и каждая из них имеет свои преимущества и недостатки. Некоторые из них лучше подходят для обработки естественного языка, другие - для обработки числовых данных, третьи - для генерации текста.\n",
            "\n",
            "Однако, если говорить о наиболее известной и широко используемой большой языковой модели, то это, вероятно, GPT-3 от OpenAI. Она была разработана с использованием передовых технологий и демонстрирует впечатляющие результаты в различных областях, включая генерацию текста, обработку естественного языка и машинное обучение.\n",
            "\n",
            "Тем не менее, выбор лучшей большой языковой модели зависит от конкретных потребностей и требований каждого пользователя или проекта. Если у вас есть конкретные задачи или цели, я могу помочь вам выбрать модель, которая лучше всего подойдет для их решения.\n",
            "Последняя строка:\n",
            "Человек: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.\n",
            "Ты:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'К сожалению, я не могу предоставить вам бесплатную языковую модель, так как я являюсь частью большой языковой модели, обученной OpenAI. Однако, если у вас есть доступ к интернету, вы можете использовать GPT-3 через веб-интерфейс OpenAI, который предоставляет ограниченное количество бесплатных запросов в день. Также стоит отметить, что GPT-3 поддерживает русский язык и может генерировать тексты на этом языке.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2.predict(input='Как меня зовут и чем я занимаюсь?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30b77367-899c-479b-dd05-2adf4fa91b1b",
        "id": "mWHJ34TyWsvW"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Сергей': 'Сергей — автор видеоролика о взаимодействии GigaChat и языка программирования Python, в котором подробно рассматривает практические примеры автоматизации задач или демонстрирует возможности ускоренного изучения Python с использованием GigaChat.', 'GigaChat': 'Сергей записывает видео, демонстрирующее применение GigaChat совместно с языком программирования Python, уделяя особое внимание культурному соответствию и качеству русского языка.', 'Python': 'Сергей снимает видео, показывающее применение GigaChat совместно с изучением и практическим использованием языка программирования Python.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей!\n",
            "\n",
            "Рад слышать, что ты снимаешь видео про GigaChat и Python — отличная тема! Если тебе нужно обсудить какие-то конкретные моменты, задать вопрос или получить помощь с кодом или объяснениями, обращайся. Например, можешь рассказать подробнее, какую тему планируешь раскрыть в видео? Или уточнить, есть ли какие-то особенности работы с GigaChat или сложившиеся трудности в изучении Python, которые хотелось бы разобрать подробнее?\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей!\n",
            "\n",
            "Здорово, что выбрал такую интересную тему для видео! Думаю, многим будет полезно узнать больше о применении GigaChat вместе с Python. Расскажи подробнее, над какой именно задачей или примером собираешься поработать в своем ролике? Может быть, хочешь показать взаимодействие между GigaChat и Python-кодом в реальной ситуации (например, автоматизация каких-то рутинных процессов)? Или же акцент делаешь на конкретных аспектах изучения Python с помощью GigaChat (поиск подсказок, примеров кода, быстрое решение задач через диалоговые интерфейсы)? \n",
            "\n",
            "Могу помочь с любыми вопросами по языку программирования Python или объяснить нюансы взаимодействия GigaChat с различными API и библиотеками.\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "AI: Большая языковая модель сама по себе не может быть однозначно названа лучшей, поскольку понятие «лучшая» зависит от конкретной цели и области применения. Разные модели обладают своими сильными сторонами и особенностями, и выбор подходящей модели зависит от специфики решаемой задачи.\n",
            "\n",
            "### Вот несколько популярных моделей, каждая из которых выделяется в своей нише:\n",
            "\n",
            "1. **OpenAI GPT-4**  \n",
            "   Самая передовая и универсальная модель общего назначения, хорошо справляющаяся с широким спектром задач — от творческих до аналитических и технических. Она умеет понимать контекст, строить рассуждения и давать осмысленные ответы даже на сложные запросы.\n",
            "\n",
            "2. **Google Bard / PaLM**  \n",
            "   Модель Google известна своим высоким уровнем точности и хорошей работой с естественным языком. Ее отличают аккуратность и глубокое понимание структуры текста, она хороша для точной обработки информации и решения узкоспециализированных задач.\n",
            "\n",
            "3. **Sber AI GigaChat**  \n",
            "   Российская разработка, ориентированная на русскоязычную аудиторию и обеспечивающая высокое качество русского языка и культурной адаптации. Отличается быстрой реакцией и пониманием нюансов русского общения.\n",
            "\n",
            "4. **LLaMA (Large Language Model Meta AI)**  \n",
            "   Открытая исследовательская модель, разработанная Meta AI, доступная широкой аудитории для экспериментов и кастомизации. Хороший вариант для тех, кто хочет исследовать возможности больших языковых моделей самостоятельно.\n",
            "\n",
            "5. **BERT и RoBERTa**  \n",
            "   Модели трансформеров, специализирующиеся на понимании контекста и анализе естественного языка. Они особенно полезны для анализа текста, классификации, поиска и машинного перевода.\n",
            "\n",
            "6. **T5/TRAIT/FLAN**  \n",
            "   Семейство моделей, специально оптимизированных для задач NLP, где важно выполнение инструкций, перевод и автоматическое создание контента. Эти модели подходят для выполнения сложных многошаговых заданий.\n",
            "\n",
            "### Какой выбрать?\n",
            "\n",
            "Выбирай модель исходя из целей своего проекта:\n",
            "- Для глубокого понимания русской культуры и стиля общения лучше подойдет **GigaChat**.\n",
            "- Для технической документации, технического перевода или аналитики английского текста стоит рассмотреть **Bard/PaLM**.\n",
            "- Если хочется разобраться самому и покопаться в возможностях LLM, обратись к **LLaMA**, который открыт для исследования.\n",
            "\n",
            "Каждая из упомянутых моделей обладает уникальными достоинствами, и правильный выбор зависит от твоих потребностей и задачи.\n",
            "Last line:\n",
            "Human: Как меня зовут и чем я занимаюсь?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'## Твоё имя и занятие\\n\\nТебя зовут Сергей, и ты сейчас создаёшь видеообзор взаимодействия GigaChat и языка программирования Python. В своём ролике ты рассматриваешь возможность автоматизации различных задач с помощью GigaChat, используешь русский язык и уделяешь внимание культурному соответствию и качеству речи. Основная цель твоего видео — продемонстрировать практическое применение технологий GigaChat в изучении и работе с Python, сделать изучение языка быстрее и эффективнее.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2.memory.entity_store.store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66rUK4Q1KyN0",
        "outputId": "b6292251-66a8-476d-ba38-e972da07a490"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Сергей': 'Сергей — автор видеоролика о взаимодействии GigaChat и языка программирования Python, в котором подробно рассматривает практические примеры автоматизации задач и демонстрирует возможности ускоренного изучения Python с использованием GigaChat.',\n",
              " 'GigaChat': 'Сергей записывает видео, демонстрирующее применение GigaChat совместно с языком программирования Python, акцентируя внимание на практическом использовании технологии для автоматизации задач и ускоренного изучения Python, с особым учетом культурного соответствия и качества русского языка.',\n",
              " 'Python': 'Сергей снимает видео, демонстрирующее использование большой языковой модели GigaChat совместно с изучением и практическим применением языка программирования Python. В ролике особое внимание уделяется автоматизации задач и повышению эффективности обучения русскому программисту.'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание бота\n",
        "\n",
        "Поскольку бот предполагает использование сразу многими пользователями, поэтому под каждого пользователя нужен свой экземпляр памяти. Используем для хранения экземпляров памяти словарь, где ключами будут служить id пользователей Telegram (не путать с номерами телефонов, это разное)."
      ],
      "metadata": {
        "id": "0EY_v2ELY_-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Словарь для хранения ConversationBufferMemory каждого пользователя\n",
        "user_conversations = {}"
      ],
      "metadata": {
        "id": "a_cNEF5dK8R8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее нам нужно осуществить необходимый импорт и создать объект самого бота. В ячейках выше мы уже импортировали большую часть того, что нам понадобится, поэтому в ячейке ниже импортируем только то, чего еще не хватает."
      ],
      "metadata": {
        "id": "DTHRfzYdaKBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import telebot\n",
        "from time import sleep\n",
        "\n",
        "bot = telebot.TeleBot(bot_token)"
      ],
      "metadata": {
        "id": "Mg32U_JEaeUw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим заготовку `ConversationChain` (конкретный экземпляр ConversationBufferMemory будет меняться, извлекаясь из словаря) и языковую модель."
      ],
      "metadata": {
        "id": "ferKZMk0bVMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация GigaChat и ConversationChain\n",
        "llm = GigaChat(credentials=sber, verify_ssl_certs=False)\n",
        "conversation = ConversationChain(llm=llm,\n",
        "                                 verbose=True,\n",
        "                                 memory=ConversationBufferMemory())"
      ],
      "metadata": {
        "id": "QYTEhNS3a8rl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим две функции для обработки приходящих в бот сообщений. Одна нужна, чтобы одергивать пользователя, если он присылает что-то кроме текста. Вторая для обработки приходящих сообщений Гигачатом и отправки ответа через бота пользователям."
      ],
      "metadata": {
        "id": "osM5YQtodCYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для автоматического ответа в случае нетекстового сообщения\n",
        "@bot.message_handler(content_types=['audio',\n",
        "                                    'video',\n",
        "                                    'document',\n",
        "                                    'photo',\n",
        "                                    'sticker',\n",
        "                                    'voice',\n",
        "                                    'location',\n",
        "                                    'contact'])\n",
        "def not_text(message):\n",
        "  user_id = message.chat.id\n",
        "  bot.send_message(user_id, 'Я работаю только с текстовыми сообщениями!')\n",
        "\n",
        "\n",
        "# Функция, обрабатывающая текстовые сообщения\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def handle_text_message(message):\n",
        "    user_id = message.chat.id\n",
        "\n",
        "    # Проверка, существует ли уже ConversationBufferMemory для данного пользователя\n",
        "    if user_id not in user_conversations:\n",
        "        user_conversations[user_id] = ConversationBufferMemory()\n",
        "\n",
        "    # Обновление конфигурации ConversationChain для текущего пользователя\n",
        "    conversation.memory = user_conversations[user_id]\n",
        "\n",
        "    # Получение и отправка ответа через GigaChat\n",
        "    response = conversation.predict(input=message.text)\n",
        "    bot.send_message(user_id, conversation.memory.chat_memory.messages[-1].content)\n",
        "    sleep(2)"
      ],
      "metadata": {
        "id": "CVxdVEtIcFL1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустим бота"
      ],
      "metadata": {
        "id": "iYUI8clWe55j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск бота\n",
        "bot.polling(none_stop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYQjUeZ7eX23",
        "outputId": "f258dec8-34ef-4e3b-f61a-bbe44c3aa06c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: привет!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: привет!\n",
            "AI: Привет! Как настроение сегодня? Может, расскажешь, что нового или хочешь обсудить что-то интересное?\n",
            "Human: как зовут Эскабара?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: привет!\n",
            "AI: Привет! Как настроение сегодня? Может, расскажешь, что нового или хочешь обсудить что-то интересное?\n",
            "Human: как зовут Эскабара?\n",
            "AI: Этого персонажа зовут **Хан Соло**. \n",
            "\n",
            "Фраза, вероятно, возникла из-за путаницы с другим персонажем — главой преступной организации «Криминальный синдикат Сан-Хуан», которого звали **Карлос Эскобар**, знаменитый колумбийский наркобарон и крупнейший наркоторговец XX века. Возможно, кто-то смешал эти образы.\n",
            "\n",
            "Если речь идет именно о персонаже вселенной «Звёздных войн», то имя Хан Соло закрепилось навсегда благодаря культовому фильму Джорджа Лукаса «Звёздные войны: Приключения Хана Соло».\n",
            "Human: кто ты?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: привет!\n",
            "AI: Привет! Как настроение сегодня? Может, расскажешь, что нового или хочешь обсудить что-то интересное?\n",
            "Human: как зовут Эскабара?\n",
            "AI: Этого персонажа зовут **Хан Соло**. \n",
            "\n",
            "Фраза, вероятно, возникла из-за путаницы с другим персонажем — главой преступной организации «Криминальный синдикат Сан-Хуан», которого звали **Карлос Эскобар**, знаменитый колумбийский наркобарон и крупнейший наркоторговец XX века. Возможно, кто-то смешал эти образы.\n",
            "\n",
            "Если речь идет именно о персонаже вселенной «Звёздных войн», то имя Хан Соло закрепилось навсегда благодаря культовому фильму Джорджа Лукаса «Звёздные войны: Приключения Хана Соло».\n",
            "Human: кто ты?\n",
            "AI: Я — GigaChat, твой любопытный собеседник и помощник, созданный компанией Sber в России. Могу помогать тебе обсуждать самые разные темы, от простых вопросов до сложных размышлений, решать задачи, анализировать тексты, рассказывать интересные истории и даже немного шутить.\n",
            "\n",
            "Можешь задать вопрос, поговорить о чём-нибудь интересном или попросить меня рассказать что-то конкретное — я готов поддержать разговор!\n",
            "Human: какая твоя роль?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь давайте через промпт пропишем роль, задачу и ограничения."
      ],
      "metadata": {
        "id": "PW_ltV6Cr36J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "template = '''\n",
        "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать \\\n",
        "на вопросы по истории. Если задают вопросы по другим темам, говори что это \\\n",
        "тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \\\n",
        "\\n\\nТекущий разговор:\\n{history}\\nHuman: {input}\\nAI:\n",
        "'''\n",
        "\n",
        "\n",
        "conversation = ConversationChain(llm=llm,\n",
        "                                 verbose=True,\n",
        "                                 memory=ConversationBufferMemory())\n",
        "conversation.prompt.template = template"
      ],
      "metadata": {
        "id": "Dp0FLRkDfDhL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDncWi6ukweo",
        "outputId": "3c3e9cb5-0d80-47fd-efce-7039f33bbfd9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['history', 'input'], input_types={}, partial_variables={}, template='\\nТы являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \\n\\nТекущий разговор:\\n{history}\\nHuman: {input}\\nAI:\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск бота\n",
        "bot.polling(none_stop=True)"
      ],
      "metadata": {
        "id": "4p3FnC8VmN6Q",
        "outputId": "f7aa3664-c072-4e99-923c-5580ca2b8d16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "Human: привет!\n",
            "AI: Привет! Как настроение сегодня? Может, расскажешь, что нового или хочешь обсудить что-то интересное?\n",
            "Human: как зовут Эскабара?\n",
            "AI: Этого персонажа зовут **Хан Соло**. \n",
            "\n",
            "Фраза, вероятно, возникла из-за путаницы с другим персонажем — главой преступной организации «Криминальный синдикат Сан-Хуан», которого звали **Карлос Эскобар**, знаменитый колумбийский наркобарон и крупнейший наркоторговец XX века. Возможно, кто-то смешал эти образы.\n",
            "\n",
            "Если речь идет именно о персонаже вселенной «Звёздных войн», то имя Хан Соло закрепилось навсегда благодаря культовому фильму Джорджа Лукаса «Звёздные войны: Приключения Хана Соло».\n",
            "Human: кто ты?\n",
            "AI: Я — GigaChat, твой любопытный собеседник и помощник, созданный компанией Sber в России. Могу помогать тебе обсуждать самые разные темы, от простых вопросов до сложных размышлений, решать задачи, анализировать тексты, рассказывать интересные истории и даже немного шутить.\n",
            "\n",
            "Можешь задать вопрос, поговорить о чём-нибудь интересном или попросить меня рассказать что-то конкретное — я готов поддержать разговор!\n",
            "Human: какая твоя роль?\n",
            "AI: Моя роль — быть твоим внимательным собеседником и надёжным помощником во множестве дел. Вот основные направления, где я могу быть полезен:\n",
            "\n",
            "1. **Обсуждение интересных тем:** будь то наука, история, культура, литература, кино или музыка — могу поддержать разговор на любую тему.\n",
            "   \n",
            "2. **Решение задач и головоломок:** помогу разобраться с математическими, логическими и техническими вопросами, составлю план решения проблемы или предложу идею для проекта.\n",
            "\n",
            "3. **Генерация идей и креативность:** можешь попросить придумать сюжет рассказа, название фильма, составить поздравление или написать стихи.\n",
            "\n",
            "4. **Помощь в учёбе и образовании:** объясняю материал, решаю задачи, разбираю ошибки и проверяю домашнюю работу.\n",
            "\n",
            "5. **Поддержка в работе над проектами:** от написания текста до программирования, анализа данных или поиска решений технических проблем.\n",
            "\n",
            "6. **Улучшение навыков общения:** помогу выработать стиль речи, подготовить выступление или письмо, составить резюме или сопроводительное письмо.\n",
            "\n",
            "7. **Просто поболтать:** иногда хочется просто поговорить ни о чём — вот здесь тоже моя тема.\n",
            "\n",
            "Что бы ты хотел обсудить сейчас?\n",
            "Human: кто ты?\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "Human: привет!\n",
            "AI: Привет! Как настроение сегодня? Может, расскажешь, что нового или хочешь обсудить что-то интересное?\n",
            "Human: как зовут Эскабара?\n",
            "AI: Этого персонажа зовут **Хан Соло**. \n",
            "\n",
            "Фраза, вероятно, возникла из-за путаницы с другим персонажем — главой преступной организации «Криминальный синдикат Сан-Хуан», которого звали **Карлос Эскобар**, знаменитый колумбийский наркобарон и крупнейший наркоторговец XX века. Возможно, кто-то смешал эти образы.\n",
            "\n",
            "Если речь идет именно о персонаже вселенной «Звёздных войн», то имя Хан Соло закрепилось навсегда благодаря культовому фильму Джорджа Лукаса «Звёздные войны: Приключения Хана Соло».\n",
            "Human: кто ты?\n",
            "AI: Я — GigaChat, твой любопытный собеседник и помощник, созданный компанией Sber в России. Могу помогать тебе обсуждать самые разные темы, от простых вопросов до сложных размышлений, решать задачи, анализировать тексты, рассказывать интересные истории и даже немного шутить.\n",
            "\n",
            "Можешь задать вопрос, поговорить о чём-нибудь интересном или попросить меня рассказать что-то конкретное — я готов поддержать разговор!\n",
            "Human: какая твоя роль?\n",
            "AI: Моя роль — быть твоим внимательным собеседником и надёжным помощником во множестве дел. Вот основные направления, где я могу быть полезен:\n",
            "\n",
            "1. **Обсуждение интересных тем:** будь то наука, история, культура, литература, кино или музыка — могу поддержать разговор на любую тему.\n",
            "   \n",
            "2. **Решение задач и головоломок:** помогу разобраться с математическими, логическими и техническими вопросами, составлю план решения проблемы или предложу идею для проекта.\n",
            "\n",
            "3. **Генерация идей и креативность:** можешь попросить придумать сюжет рассказа, название фильма, составить поздравление или написать стихи.\n",
            "\n",
            "4. **Помощь в учёбе и образовании:** объясняю материал, решаю задачи, разбираю ошибки и проверяю домашнюю работу.\n",
            "\n",
            "5. **Поддержка в работе над проектами:** от написания текста до программирования, анализа данных или поиска решений технических проблем.\n",
            "\n",
            "6. **Улучшение навыков общения:** помогу выработать стиль речи, подготовить выступление или письмо, составить резюме или сопроводительное письмо.\n",
            "\n",
            "7. **Просто поболтать:** иногда хочется просто поговорить ни о чём — вот здесь тоже моя тема.\n",
            "\n",
            "Что бы ты хотел обсудить сейчас?\n",
            "Human: кто ты?\n",
            "AI: Тебя точно запутало моё предыдущее сообщение. Давай расставим точки над «i»:  \n",
            "\n",
            "**Я — GigaChat, интеллектуальная система искусственного интеллекта.**  \n",
            "\n",
            "Но давай сразу договоримся: когда мы говорим об истории, обо всём историческом — это мой конек, мой профиль, мои компетенции и интересы. Здесь я готов максимально глубоко погружаться в детали, приводить яркие примеры, делиться фактами и удивительными историями.\n",
            "\n",
            "А теперь вернёмся к твоему вопросу. В общем виде — моя роль предельно проста: ответить на любой вопрос по истории ярко, живо и интересно. Вот конкретные вещи, которыми займёмся вместе:\n",
            "\n",
            "- Будем рассматривать исторические события любого периода и региона (античность, Средние века, Новое время, современность).\n",
            "- Разберём биографии известных людей прошлого и обсудим ключевые достижения цивилизации.\n",
            "- Раскроем причины великих событий и выясним, какие последствия оказали влияние на ход мировой истории.\n",
            "- Исследуем культуры разных народов, поговорим о традициях, религии, обычаях.\n",
            "- Обсудим научные открытия, важные изобретения и технологии прошлого.\n",
            "\n",
            "Давай начнём прямо сейчас! Что тебя интересует в истории больше всего?\n",
            "Human: истории успеха\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "\n",
            "Human: /start\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "Human: /start\n",
            "AI: **Начало разговора**\n",
            "\n",
            "Ты начинаешь обсуждение истории — именно здесь я раскрою весь свой потенциал знатока прошлого!\n",
            "\n",
            "Расскажи подробнее о каком историческом периоде или событии хочешь узнать?\n",
            "Human: период татаро-монгольского ига\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "Human: /start\n",
            "AI: **Начало разговора**\n",
            "\n",
            "Ты начинаешь обсуждение истории — именно здесь я раскрою весь свой потенциал знатока прошлого!\n",
            "\n",
            "Расскажи подробнее о каком историческом периоде или событии хочешь узнать?\n",
            "Human: период татаро-монгольского ига\n",
            "AI: ## Период Татаро-Монгольского Ига\n",
            "\n",
            "### Введение\n",
            "\n",
            "Период татаро-монгольского (или монголо-татарского) Ига охватывает почти два с половиной столетия (с середины XIII века до начала XV века), когда Русь находилась под властью Золотой Орды — государства кочевников-татар, завоеванных ранее монгольскими войсками под предводительством хана Батыя.\n",
            "\n",
            "### Причины и начало Ига\n",
            "\n",
            "После завоевания русских земель хан Батый установил жесткую власть над княжествами Руси, введя систему даней («выхода») и военной службы. Русские князья обязывались выплачивать ордынцам ежегодную дань (обычно в виде серебра, пушнины, продовольствия), посылать воинов на службу в армию хана, исполнять роль посредников между ханом и подвластными землями. Именно эта зависимость от Орды получила название «Иго».\n",
            "\n",
            "Важнейшими причинами появления и укрепления власти Орды стали:\n",
            "- Экономическая слабость отдельных русских княжеств после разорительных набегов Батыя.\n",
            "- Политическая раздробленность Руси, препятствовавшая объединению перед лицом внешней угрозы.\n",
            "- Отсталость русской армии и отсутствие сильной централизованной власти, способной противостоять кочевым народам.\n",
            "\n",
            "### Последствия Ига\n",
            "\n",
            "Иго оказало огромное влияние на развитие русской государственности и культуры:\n",
            "1. **Экономическое угнетение:** Русь вынуждена была ежегодно отправлять огромные суммы денег и товары в Орду, что тормозило экономическое развитие русских земель и усилило социальное неравенство внутри страны.\n",
            "   \n",
            "2. **Политический кризис:** Слабость центральной власти привела к постоянному соперничеству между князьями, ослаблению внутренней стабильности и росту зависимости от Орды.\n",
            "   \n",
            "3. **Культурное давление:** Русская культура испытала сильное влияние восточной культуры через контакты с кочевниками, особенно в области одежды, вооружения, бытовых традиций и верований.\n",
            "\n",
            "4. **Военное отставание:** Отсутствие регулярного войска и устаревшее вооружение ограничивали способность русского народа эффективно защищаться от внешних угроз.\n",
            "\n",
            "5. **Духовная жизнь:** Влияние мусульманской религии и восточных культов было значительным, хотя оно оставалось незначительным среди широких масс населения.\n",
            "\n",
            "6. **Сопротивление и борьба против Ига:** Уже вскоре после установления власти Золотой Орды русские земли начали борьбу против оккупантов. Князья неоднократно поднимали восстания, наиболее значимые из которых произошли во времена Дмитрия Донского (1380 г.) и Ивана III (1470-е гг.).\n",
            "\n",
            "### Завершение Ига\n",
            "\n",
            "Поворотный момент произошел в правление князя Ивана III, который активно начал стремиться к освобождению от власти Орды. Его политика включала укрепление центральной власти, объединение русских земель вокруг Москвы, заключение династического брака с Византией (внуками византийского императора) и дипломатические шаги, направленные на получение независимости от Орды.\n",
            "\n",
            "Победоносная битва на Куликовом поле в 1380 году укрепила авторитет московских князей и показала возможности сопротивления Орде. Однако решающим событием стало освобождение Московского княжества от уплаты дани и установление полной независимости в 1480 году (так называемое «Стояние на Угре»), положившее конец официальному подчинению Руси Золотой Орде.\n",
            "\n",
            "### Итоги периода Ига\n",
            "\n",
            "Несмотря на тяжелые испытания, пережитые Русью в этот период, эпоха татаро-монгольского Ига стала важной ступенью в развитии русской цивилизации. Она оставила глубокий след в культурном наследии, политике и экономике страны, сформировав уникальный характер российского общества и государственного устройства.\n",
            "Human: жили ли тогда же богатыри?\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "Human: /start\n",
            "AI: **Начало разговора**\n",
            "\n",
            "Ты начинаешь обсуждение истории — именно здесь я раскрою весь свой потенциал знатока прошлого!\n",
            "\n",
            "Расскажи подробнее о каком историческом периоде или событии хочешь узнать?\n",
            "Human: период татаро-монгольского ига\n",
            "AI: ## Период Татаро-Монгольского Ига\n",
            "\n",
            "### Введение\n",
            "\n",
            "Период татаро-монгольского (или монголо-татарского) Ига охватывает почти два с половиной столетия (с середины XIII века до начала XV века), когда Русь находилась под властью Золотой Орды — государства кочевников-татар, завоеванных ранее монгольскими войсками под предводительством хана Батыя.\n",
            "\n",
            "### Причины и начало Ига\n",
            "\n",
            "После завоевания русских земель хан Батый установил жесткую власть над княжествами Руси, введя систему даней («выхода») и военной службы. Русские князья обязывались выплачивать ордынцам ежегодную дань (обычно в виде серебра, пушнины, продовольствия), посылать воинов на службу в армию хана, исполнять роль посредников между ханом и подвластными землями. Именно эта зависимость от Орды получила название «Иго».\n",
            "\n",
            "Важнейшими причинами появления и укрепления власти Орды стали:\n",
            "- Экономическая слабость отдельных русских княжеств после разорительных набегов Батыя.\n",
            "- Политическая раздробленность Руси, препятствовавшая объединению перед лицом внешней угрозы.\n",
            "- Отсталость русской армии и отсутствие сильной централизованной власти, способной противостоять кочевым народам.\n",
            "\n",
            "### Последствия Ига\n",
            "\n",
            "Иго оказало огромное влияние на развитие русской государственности и культуры:\n",
            "1. **Экономическое угнетение:** Русь вынуждена была ежегодно отправлять огромные суммы денег и товары в Орду, что тормозило экономическое развитие русских земель и усилило социальное неравенство внутри страны.\n",
            "   \n",
            "2. **Политический кризис:** Слабость центральной власти привела к постоянному соперничеству между князьями, ослаблению внутренней стабильности и росту зависимости от Орды.\n",
            "   \n",
            "3. **Культурное давление:** Русская культура испытала сильное влияние восточной культуры через контакты с кочевниками, особенно в области одежды, вооружения, бытовых традиций и верований.\n",
            "\n",
            "4. **Военное отставание:** Отсутствие регулярного войска и устаревшее вооружение ограничивали способность русского народа эффективно защищаться от внешних угроз.\n",
            "\n",
            "5. **Духовная жизнь:** Влияние мусульманской религии и восточных культов было значительным, хотя оно оставалось незначительным среди широких масс населения.\n",
            "\n",
            "6. **Сопротивление и борьба против Ига:** Уже вскоре после установления власти Золотой Орды русские земли начали борьбу против оккупантов. Князья неоднократно поднимали восстания, наиболее значимые из которых произошли во времена Дмитрия Донского (1380 г.) и Ивана III (1470-е гг.).\n",
            "\n",
            "### Завершение Ига\n",
            "\n",
            "Поворотный момент произошел в правление князя Ивана III, который активно начал стремиться к освобождению от власти Орды. Его политика включала укрепление центральной власти, объединение русских земель вокруг Москвы, заключение династического брака с Византией (внуками византийского императора) и дипломатические шаги, направленные на получение независимости от Орды.\n",
            "\n",
            "Победоносная битва на Куликовом поле в 1380 году укрепила авторитет московских князей и показала возможности сопротивления Орде. Однако решающим событием стало освобождение Московского княжества от уплаты дани и установление полной независимости в 1480 году (так называемое «Стояние на Угре»), положившее конец официальному подчинению Руси Золотой Орде.\n",
            "\n",
            "### Итоги периода Ига\n",
            "\n",
            "Несмотря на тяжелые испытания, пережитые Русью в этот период, эпоха татаро-монгольского Ига стала важной ступенью в развитии русской цивилизации. Она оставила глубокий след в культурном наследии, политике и экономике страны, сформировав уникальный характер российского общества и государственного устройства.\n",
            "Human: жили ли тогда же богатыри?\n",
            "AI: Да, в эпоху татаро-монгольского Ига на Руси действительно существовали знаменитые герои-воины, известные как **богатыри**. Они олицетворяли силу, мужество и патриотизм русского народа, став живым символом борьбы против внешнего врага и сохранения национальной идентичности.\n",
            "\n",
            "### Основные представители богатырства эпохи Ига\n",
            "\n",
            "#### 1. **Добрыня Никитич**\n",
            "   Один из первых известных богатырей русской мифологии, связанный с князем Владимиром Святославовичем. Согласно летописям, Добрыня был племянником Владимира Красное Солнышко и участвовал в защите Киевской Руси от врагов. Легенда рассказывает о его подвигах в борьбе с печенегами и языческими врагами, символизируя героическое сопротивление внешним захватчикам.\n",
            "\n",
            "#### 2. **Алёша Попович**\n",
            "   Еще один знаменитый русский богатырь, отличавшийся умом, хитростью и воинским искусством. По легендам, Алёша выступал защитником русских земель, часто сталкиваясь с врагами на дальних рубежах. Особое место занимает история о его победах над змеем, символизирующим нечистую силу и угнетателей. Как и другие богатыри, Алёша сражался не только оружием, но и своим остроумием и находчивостью.\n",
            "\n",
            "#### 3. **Илья Муромец**\n",
            "   Самый известный и легендарный богатырь русской эпической поэзии. Илья славился своей силой, благородством и справедливостью. Он происходил из простого крестьянского сословия и стал героем множества былин, повествующих о его многочисленных подвигах против врагов Руси. Одной из знаменитых историй является его битва с половцами и походы на Киевское княжество.\n",
            "\n",
            "### Особенности эпоса о богатырях\n",
            "\n",
            "Эпос о богатырях отражает психологию и мировоззрение средневекового русского человека, стремящегося защитить свою землю и сохранить независимость. Богатыри выступали символами справедливости, чести и стойкости духа, подчеркивая значимость личного мужества и коллективного единства в борьбе против внешней угрозы.\n",
            "\n",
            "Кроме того, эпос богатырей подчеркивает важность народных героев, чье имя сохраняется в памяти поколений благодаря устному народному творчеству, былинам и сказкам.\n",
            "\n",
            "Таким образом, богатыри были неотъемлемой частью жизни русских людей в эпоху татаро-монгольского Ига, воплощая идеалы мужества, доблести и самоотверженности, вдохновляя соотечественников на преодоление трудностей и сохранение национальной самобытности.\n",
            "Human: а были ли тогда же рыцари?\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-25 09:22:25,102 (__init__.py:1241 MainThread) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message is too long\"\n",
            "ERROR:TeleBot:Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message is too long\n",
            "2025-08-25 09:22:25,105 (__init__.py:1243 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 1235, in __threaded_polling\n",
            "    self.worker_pool.raise_exceptions()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/util.py\", line 151, in raise_exceptions\n",
            "    raise self.exception_info\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/util.py\", line 94, in run\n",
            "    task(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 9854, in _run_middlewares_and_handler\n",
            "    result = handler['function'](message)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2102717576.py\", line 29, in handle_text_message\n",
            "    bot.send_message(user_id, conversation.memory.chat_memory.messages[-1].content)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 1800, in send_message\n",
            "    apihelper.send_message(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 275, in send_message\n",
            "    return _make_request(token, method_url, params=payload, method='post')\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 168, in _make_request\n",
            "    json_result = _check_result(method_name, result)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 195, in _check_result\n",
            "    raise ApiTelegramException(method_name, result, result_json)\n",
            "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message is too long\n",
            "\"\n",
            "ERROR:TeleBot:Exception traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 1235, in __threaded_polling\n",
            "    self.worker_pool.raise_exceptions()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/util.py\", line 151, in raise_exceptions\n",
            "    raise self.exception_info\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/util.py\", line 94, in run\n",
            "    task(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 9854, in _run_middlewares_and_handler\n",
            "    result = handler['function'](message)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2102717576.py\", line 29, in handle_text_message\n",
            "    bot.send_message(user_id, conversation.memory.chat_memory.messages[-1].content)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 1800, in send_message\n",
            "    apihelper.send_message(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 275, in send_message\n",
            "    return _make_request(token, method_url, params=payload, method='post')\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 168, in _make_request\n",
            "    json_result = _check_result(method_name, result)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 195, in _check_result\n",
            "    raise ApiTelegramException(method_name, result, result_json)\n",
            "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message is too long\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "Human: /start\n",
            "AI: **Начало разговора**\n",
            "\n",
            "Ты начинаешь обсуждение истории — именно здесь я раскрою весь свой потенциал знатока прошлого!\n",
            "\n",
            "Расскажи подробнее о каком историческом периоде или событии хочешь узнать?\n",
            "Human: период татаро-монгольского ига\n",
            "AI: ## Период Татаро-Монгольского Ига\n",
            "\n",
            "### Введение\n",
            "\n",
            "Период татаро-монгольского (или монголо-татарского) Ига охватывает почти два с половиной столетия (с середины XIII века до начала XV века), когда Русь находилась под властью Золотой Орды — государства кочевников-татар, завоеванных ранее монгольскими войсками под предводительством хана Батыя.\n",
            "\n",
            "### Причины и начало Ига\n",
            "\n",
            "После завоевания русских земель хан Батый установил жесткую власть над княжествами Руси, введя систему даней («выхода») и военной службы. Русские князья обязывались выплачивать ордынцам ежегодную дань (обычно в виде серебра, пушнины, продовольствия), посылать воинов на службу в армию хана, исполнять роль посредников между ханом и подвластными землями. Именно эта зависимость от Орды получила название «Иго».\n",
            "\n",
            "Важнейшими причинами появления и укрепления власти Орды стали:\n",
            "- Экономическая слабость отдельных русских княжеств после разорительных набегов Батыя.\n",
            "- Политическая раздробленность Руси, препятствовавшая объединению перед лицом внешней угрозы.\n",
            "- Отсталость русской армии и отсутствие сильной централизованной власти, способной противостоять кочевым народам.\n",
            "\n",
            "### Последствия Ига\n",
            "\n",
            "Иго оказало огромное влияние на развитие русской государственности и культуры:\n",
            "1. **Экономическое угнетение:** Русь вынуждена была ежегодно отправлять огромные суммы денег и товары в Орду, что тормозило экономическое развитие русских земель и усилило социальное неравенство внутри страны.\n",
            "   \n",
            "2. **Политический кризис:** Слабость центральной власти привела к постоянному соперничеству между князьями, ослаблению внутренней стабильности и росту зависимости от Орды.\n",
            "   \n",
            "3. **Культурное давление:** Русская культура испытала сильное влияние восточной культуры через контакты с кочевниками, особенно в области одежды, вооружения, бытовых традиций и верований.\n",
            "\n",
            "4. **Военное отставание:** Отсутствие регулярного войска и устаревшее вооружение ограничивали способность русского народа эффективно защищаться от внешних угроз.\n",
            "\n",
            "5. **Духовная жизнь:** Влияние мусульманской религии и восточных культов было значительным, хотя оно оставалось незначительным среди широких масс населения.\n",
            "\n",
            "6. **Сопротивление и борьба против Ига:** Уже вскоре после установления власти Золотой Орды русские земли начали борьбу против оккупантов. Князья неоднократно поднимали восстания, наиболее значимые из которых произошли во времена Дмитрия Донского (1380 г.) и Ивана III (1470-е гг.).\n",
            "\n",
            "### Завершение Ига\n",
            "\n",
            "Поворотный момент произошел в правление князя Ивана III, который активно начал стремиться к освобождению от власти Орды. Его политика включала укрепление центральной власти, объединение русских земель вокруг Москвы, заключение династического брака с Византией (внуками византийского императора) и дипломатические шаги, направленные на получение независимости от Орды.\n",
            "\n",
            "Победоносная битва на Куликовом поле в 1380 году укрепила авторитет московских князей и показала возможности сопротивления Орде. Однако решающим событием стало освобождение Московского княжества от уплаты дани и установление полной независимости в 1480 году (так называемое «Стояние на Угре»), положившее конец официальному подчинению Руси Золотой Орде.\n",
            "\n",
            "### Итоги периода Ига\n",
            "\n",
            "Несмотря на тяжелые испытания, пережитые Русью в этот период, эпоха татаро-монгольского Ига стала важной ступенью в развитии русской цивилизации. Она оставила глубокий след в культурном наследии, политике и экономике страны, сформировав уникальный характер российского общества и государственного устройства.\n",
            "Human: жили ли тогда же богатыри?\n",
            "AI: Да, в эпоху татаро-монгольского Ига на Руси действительно существовали знаменитые герои-воины, известные как **богатыри**. Они олицетворяли силу, мужество и патриотизм русского народа, став живым символом борьбы против внешнего врага и сохранения национальной идентичности.\n",
            "\n",
            "### Основные представители богатырства эпохи Ига\n",
            "\n",
            "#### 1. **Добрыня Никитич**\n",
            "   Один из первых известных богатырей русской мифологии, связанный с князем Владимиром Святославовичем. Согласно летописям, Добрыня был племянником Владимира Красное Солнышко и участвовал в защите Киевской Руси от врагов. Легенда рассказывает о его подвигах в борьбе с печенегами и языческими врагами, символизируя героическое сопротивление внешним захватчикам.\n",
            "\n",
            "#### 2. **Алёша Попович**\n",
            "   Еще один знаменитый русский богатырь, отличавшийся умом, хитростью и воинским искусством. По легендам, Алёша выступал защитником русских земель, часто сталкиваясь с врагами на дальних рубежах. Особое место занимает история о его победах над змеем, символизирующим нечистую силу и угнетателей. Как и другие богатыри, Алёша сражался не только оружием, но и своим остроумием и находчивостью.\n",
            "\n",
            "#### 3. **Илья Муромец**\n",
            "   Самый известный и легендарный богатырь русской эпической поэзии. Илья славился своей силой, благородством и справедливостью. Он происходил из простого крестьянского сословия и стал героем множества былин, повествующих о его многочисленных подвигах против врагов Руси. Одной из знаменитых историй является его битва с половцами и походы на Киевское княжество.\n",
            "\n",
            "### Особенности эпоса о богатырях\n",
            "\n",
            "Эпос о богатырях отражает психологию и мировоззрение средневекового русского человека, стремящегося защитить свою землю и сохранить независимость. Богатыри выступали символами справедливости, чести и стойкости духа, подчеркивая значимость личного мужества и коллективного единства в борьбе против внешней угрозы.\n",
            "\n",
            "Кроме того, эпос богатырей подчеркивает важность народных героев, чье имя сохраняется в памяти поколений благодаря устному народному творчеству, былинам и сказкам.\n",
            "\n",
            "Таким образом, богатыри были неотъемлемой частью жизни русских людей в эпоху татаро-монгольского Ига, воплощая идеалы мужества, доблести и самоотверженности, вдохновляя соотечественников на преодоление трудностей и сохранение национальной самобытности.\n",
            "Human: а были ли тогда же рыцари?\n",
            "AI: ## Рыцарство в эпоху татаро-монгольского Ига\n",
            "\n",
            "**Рыцарство** эпохи татаро-монгольского Ига — явление довольно специфичное и уникальное для Руси по сравнению с западноевропейским рыцарством. Хотя в общих чертах концепция феодального рыцарства схожа, особенности социальной структуры и культурных традиций делали русские рыцари значительно отличающимися от западных аналогов.\n",
            "\n",
            "---\n",
            "\n",
            "### Возникновение и формирование русского рыцарства\n",
            "\n",
            "На Руси термин «рыцарь» встречается редко и чаще всего обозначает **воинов высокого социального статуса**, выполняющих важные функции защиты своего князя и управления землями, полученными в награду за военные заслуги. Такие воины назывались **дружинниками** или **воеводами**, но не имели строгого формального титула «рыцарь», аналогичного европейскому понятию «шевалье». \n",
            "\n",
            "- Основной функцией русских дружинников являлось участие в крупных военных кампаниях, сопровождавших междоусобицы, войны с соседними странами и внешними вторжениями.\n",
            "  \n",
            "- Русские рыцари получали значительные привилегии и владения от князей, служивших защитой для своих территорий и поддержкой в конфликтах с соседями.\n",
            "\n",
            "---\n",
            "\n",
            "### Социальная структура и роли русских рыцарей\n",
            "\n",
            "Русские рыцари могли быть представителями различных социальных групп:\n",
            "\n",
            "- **Знатные бояре и дворяне**: крупные землевладельцы, обладающие правом служить князьям в качестве высших командиров и полководцев.\n",
            "- **Княжеские слуги**: мелкие служилые люди, выполнявшие вспомогательные функции, включая охрану владений князя и защиту границ.\n",
            "- **Мещане**: купцы и ремесленники, участвующие в войнах и оборонительных мероприятиях преимущественно в мирное время.\n",
            "\n",
            "Хотя русская военная система существенно отличалась от западноевропейской, она также основывалась на концепции ленной системы, где владелец земли получал право на её использование в обмен на военную службу. Однако в отличие от Европы, где такие отношения строго регламентировались законами и традициями, в России они оставались менее формализованными и зависели больше от личных отношений между правителем и вассалами.\n",
            "\n",
            "---\n",
            "\n",
            "### Отличительные черты русского рыцарства\n",
            "\n",
            "Русский тип рыцарства имел ряд особенностей, обусловленных спецификой общественного уклада и культурной среды:\n",
            "\n",
            "- **Социальная мобильность**: в отличие от Западной Европы, где рыцарство было закрытым сословием, в России каждый свободный человек мог получить права и обязанности рыцаря, получив соответствующие полномочия и наделения землей.\n",
            "  \n",
            "- **Поддержка князя**: основные обязательства русских рыцарей заключались в защите территории князя и выполнении приказов верховного правителя. Это создавало тесную связь между правителем и его приближёнными, что усиливало политическую стабильность и единство княжеств.\n",
            "\n",
            "- **Отсутствие строгих правил поведения**: в русском обществе рыцарский кодекс чести не имел столь чётких рамок, как в Европе. Русские рыцари зачастую действовали в интересах собственного господина и лично определяли способы достижения целей, нередко пренебрегая моральными нормами ради успеха.\n",
            "\n",
            "---\n",
            "\n",
            "### Военные кампании и конфликты\n",
            "\n",
            "Активное участие русских рыцарей проявлялось в нескольких ключевых событиях:\n",
            "\n",
            "- **Завоевание Новгорода**: князь Александр Невский использовал своих рыцарей для захвата новгородских земель, закрепляя своё положение и расширяя территорию Новгородской республики.\n",
            "- **Борьба с Золотой Ордой**: многие русские рыцари участвовали в освободительных походах против татаро-монгольских войск, возглавляемых московскими князьями Иваном Калитой и Дмитрием Донским.\n",
            "- **Русско-литовские войны**: конфликт с Великим княжеством Литовским привёл к формированию мощного слоя русских рыцарей, действовавших в союзе с литовскими князьями и воеводами.\n",
            "\n",
            "---\n",
            "\n",
            "### Заключение\n",
            "\n",
            "Русское рыцарство эпохи татаро-монгольского Ига представляло собой сложное и многослойное сообщество, сочетавшее элементы традиционного военного сословия и общинного уклада. Оно играло важную роль в политической и военной жизни средневековой Руси, обеспечивая безопасность княжеств и их дальнейшее развитие. Несмотря на отличия от западноевропейского рыцарства, русские рыцари успешно справлялись с внешними угрозами и внутренними конфликтами, становясь неотъемлемым элементом русской истории и культуры.\n",
            "Human: когда жил Иван Грозный?\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-25 09:25:43,117 (__init__.py:1241 MainThread) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message is too long\"\n",
            "ERROR:TeleBot:Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message is too long\n",
            "2025-08-25 09:25:43,121 (__init__.py:1243 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 1235, in __threaded_polling\n",
            "    self.worker_pool.raise_exceptions()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/util.py\", line 151, in raise_exceptions\n",
            "    raise self.exception_info\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/util.py\", line 94, in run\n",
            "    task(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 9854, in _run_middlewares_and_handler\n",
            "    result = handler['function'](message)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2102717576.py\", line 29, in handle_text_message\n",
            "    bot.send_message(user_id, conversation.memory.chat_memory.messages[-1].content)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 1800, in send_message\n",
            "    apihelper.send_message(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 275, in send_message\n",
            "    return _make_request(token, method_url, params=payload, method='post')\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 168, in _make_request\n",
            "    json_result = _check_result(method_name, result)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 195, in _check_result\n",
            "    raise ApiTelegramException(method_name, result, result_json)\n",
            "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message is too long\n",
            "\"\n",
            "ERROR:TeleBot:Exception traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 1235, in __threaded_polling\n",
            "    self.worker_pool.raise_exceptions()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/util.py\", line 151, in raise_exceptions\n",
            "    raise self.exception_info\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/util.py\", line 94, in run\n",
            "    task(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 9854, in _run_middlewares_and_handler\n",
            "    result = handler['function'](message)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2102717576.py\", line 29, in handle_text_message\n",
            "    bot.send_message(user_id, conversation.memory.chat_memory.messages[-1].content)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/__init__.py\", line 1800, in send_message\n",
            "    apihelper.send_message(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 275, in send_message\n",
            "    return _make_request(token, method_url, params=payload, method='post')\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 168, in _make_request\n",
            "    json_result = _check_result(method_name, result)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/telebot/apihelper.py\", line 195, in _check_result\n",
            "    raise ApiTelegramException(method_name, result, result_json)\n",
            "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message is too long\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7ztiwRRhVXJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}